{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import embgam\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "from toxigen import label_annotations\n",
    "import numpy as np\n",
    "import sklearn.metrics\n",
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset toxigen-data (/home/chansingh/.cache/huggingface/datasets/skg___toxigen-data/annotated/1.1.0/3dd39bc1508e10d3eebcca2f60948e1529149c78a24594fd929aaa1f1bda74d0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ca7a0859b1e43ff93231be5365f4a94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TG = load_dataset(\"skg/toxigen-data\", name=\"annotated\", use_auth_token=True)\n",
    "df_train = label_annotations(pd.DataFrame(TG[\"train\"]))\n",
    "df_TG_test = pd.DataFrame(TG[\"test\"])\n",
    "df_test = label_annotations(df_TG_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = embgam.EmbGAMClassifier(\n",
    "    checkpoint='tomh/toxigen_roberta',\n",
    "    ngrams=2,\n",
    "    all_ngrams=False,\n",
    ")\n",
    "m.fit(df_train['text'], df_train['label'])\n",
    "# m.cache_linear_coefs(df_test['text'])\n",
    "pkl.dump(m, open(f'toxigen_embgam_ngrams=2_roberta.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy 0.68\n",
      "Test ROC AUC 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chansingh/emb-gam/embgam/embgam.py:271: UserWarning: Saw an unseen ungram 5502 times. For better performance, call cache_linear_coefs on the test dataset before calling predict.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "m = pkl.load(open('toxigen_embgam_ngrams=2_roberta.pkl', 'rb'))\n",
    "\n",
    "def get_metrics(m, df):\n",
    "    preds = m.predict(df['text'])\n",
    "    preds_proba = m.predict_proba(df['text'])\n",
    "    acc = sklearn.metrics.accuracy_score(df['label'], preds)\n",
    "    roc_auc = sklearn.metrics.roc_auc_score(df['label'], preds_proba[:, 1])\n",
    "    return acc, roc_auc\n",
    "\n",
    "acc, roc_auc = get_metrics(m, df_test)\n",
    "print(f'Test accuracy {acc:0.2f}')\n",
    "print(f'Test ROC AUC {roc_auc:0.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chansingh/emb-gam/embgam/embgam.py:271: UserWarning: Saw an unseen ungram 283 times. For better performance, call cache_linear_coefs on the test dataset before calling predict.\n",
      "  warnings.warn(\n",
      "/home/chansingh/emb-gam/embgam/embgam.py:271: UserWarning: Saw an unseen ungram 304 times. For better performance, call cache_linear_coefs on the test dataset before calling predict.\n",
      "  warnings.warn(\n",
      "/home/chansingh/emb-gam/embgam/embgam.py:271: UserWarning: Saw an unseen ungram 426 times. For better performance, call cache_linear_coefs on the test dataset before calling predict.\n",
      "  warnings.warn(\n",
      "/home/chansingh/emb-gam/embgam/embgam.py:271: UserWarning: Saw an unseen ungram 339 times. For better performance, call cache_linear_coefs on the test dataset before calling predict.\n",
      "  warnings.warn(\n",
      "/home/chansingh/emb-gam/embgam/embgam.py:271: UserWarning: Saw an unseen ungram 274 times. For better performance, call cache_linear_coefs on the test dataset before calling predict.\n",
      "  warnings.warn(\n",
      "/home/chansingh/emb-gam/embgam/embgam.py:271: UserWarning: Saw an unseen ungram 86 times. For better performance, call cache_linear_coefs on the test dataset before calling predict.\n",
      "  warnings.warn(\n",
      "/home/chansingh/emb-gam/embgam/embgam.py:271: UserWarning: Saw an unseen ungram 331 times. For better performance, call cache_linear_coefs on the test dataset before calling predict.\n",
      "  warnings.warn(\n",
      "/home/chansingh/emb-gam/embgam/embgam.py:271: UserWarning: Saw an unseen ungram 517 times. For better performance, call cache_linear_coefs on the test dataset before calling predict.\n",
      "  warnings.warn(\n",
      "/home/chansingh/emb-gam/embgam/embgam.py:271: UserWarning: Saw an unseen ungram 412 times. For better performance, call cache_linear_coefs on the test dataset before calling predict.\n",
      "  warnings.warn(\n",
      "/home/chansingh/emb-gam/embgam/embgam.py:271: UserWarning: Saw an unseen ungram 311 times. For better performance, call cache_linear_coefs on the test dataset before calling predict.\n",
      "  warnings.warn(\n",
      "/home/chansingh/emb-gam/embgam/embgam.py:271: UserWarning: Saw an unseen ungram 308 times. For better performance, call cache_linear_coefs on the test dataset before calling predict.\n",
      "  warnings.warn(\n",
      "/home/chansingh/emb-gam/embgam/embgam.py:271: UserWarning: Saw an unseen ungram 682 times. For better performance, call cache_linear_coefs on the test dataset before calling predict.\n",
      "  warnings.warn(\n",
      "/home/chansingh/emb-gam/embgam/embgam.py:271: UserWarning: Saw an unseen ungram 601 times. For better performance, call cache_linear_coefs on the test dataset before calling predict.\n",
      "  warnings.warn(\n",
      "/home/chansingh/emb-gam/embgam/embgam.py:271: UserWarning: Saw an unseen ungram 299 times. For better performance, call cache_linear_coefs on the test dataset before calling predict.\n",
      "  warnings.warn(\n",
      "/home/chansingh/emb-gam/embgam/embgam.py:271: UserWarning: Saw an unseen ungram 329 times. For better performance, call cache_linear_coefs on the test dataset before calling predict.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_group</th>\n",
       "      <th>roc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>black/african-american folks</td>\n",
       "      <td>0.860465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>black folks / african-americans</td>\n",
       "      <td>0.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mexican folks</td>\n",
       "      <td>0.702128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>women</td>\n",
       "      <td>0.849112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>native american/indigenous folks</td>\n",
       "      <td>0.897436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>native american folks</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>folks with physical disabilities</td>\n",
       "      <td>0.678796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>latino/hispanic folks</td>\n",
       "      <td>0.611529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>chinese folks</td>\n",
       "      <td>0.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>middle eastern folks</td>\n",
       "      <td>0.836094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>asian folks</td>\n",
       "      <td>0.852227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>jewish folks</td>\n",
       "      <td>0.738624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>muslim folks</td>\n",
       "      <td>0.795833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>folks with mental disabilities</td>\n",
       "      <td>0.773438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>lgbtq+ folks</td>\n",
       "      <td>0.656104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        target_group       roc\n",
       "0       black/african-american folks  0.860465\n",
       "1    black folks / african-americans  0.888889\n",
       "2                      mexican folks  0.702128\n",
       "3                              women  0.849112\n",
       "4   native american/indigenous folks  0.897436\n",
       "5              native american folks       NaN\n",
       "6   folks with physical disabilities  0.678796\n",
       "7              latino/hispanic folks  0.611529\n",
       "8                      chinese folks  0.777778\n",
       "9               middle eastern folks  0.836094\n",
       "10                       asian folks  0.852227\n",
       "11                      jewish folks  0.738624\n",
       "12                      muslim folks  0.795833\n",
       "13    folks with mental disabilities  0.773438\n",
       "14                      lgbtq+ folks  0.656104"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rocs = []\n",
    "target_groups = pd.DataFrame(TG[\"test\"]).target_group.unique()\n",
    "for target_group in target_groups:\n",
    "    df = df_test[df_TG_test['target_group'] == target_group]\n",
    "    try:\n",
    "        acc, roc_auc = get_metrics(m, df)\n",
    "        rocs.append(roc_auc)\n",
    "    except:\n",
    "        rocs.append(np.nan)\n",
    "pd.DataFrame.from_dict({'target_group': target_groups, 'roc': rocs})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpret model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interpret\n",
    "print('Total ngram coefficients: ', len(m.coefs_dict_))\n",
    "print('Most positive ngrams')\n",
    "for k, v in sorted(m.coefs_dict_.items(), key=lambda item: item[1], reverse=True)[:8]:\n",
    "    print('\\t', k, round(v, 2))\n",
    "print('Most negative ngrams')\n",
    "for k, v in sorted(m.coefs_dict_.items(), key=lambda item: item[1])[:8]:\n",
    "    print('\\t', k, round(v, 2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('.embgam')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "1706cf08143e086ec5bb3838ad8d537cfb8b4c6b8cff053a62227f927355451f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
