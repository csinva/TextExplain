{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook shows a simple demo of how to use Aug-imodels (`AugLinearClassifier` and `AugTreeClassifier`). These models use LLMs to augment trnsparent models (e.g. GAMs and decision trees) to improve their performance.\n",
    "\n",
    "Both follow a simple sklearn-style interface, but may be slow to fit (because of the LLM augmentation). Both are extremely fast at test time, as they no longer use an LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from imodelsx import AugLinearClassifier, AugTreeClassifier\n",
    "# from imodelsx import AugGAMClassifier as AugLinearClassifier\n",
    "import datasets\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load some data\n",
    "Here, we load some training/validation data from the rotten-tomatoes movie dataset. To make things fast, we restrict our training and testing datasets to only 300 examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset = datasets.load_dataset('rotten_tomatoes')['train']\n",
    "dset = dset.select(np.random.choice(len(dset), size=300, replace=False))\n",
    "\n",
    "dset_val = datasets.load_dataset('rotten_tomatoes')['validation']\n",
    "dset_val = dset_val.select(np.random.choice(\n",
    "    len(dset_val), size=300, replace=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aug-Linear"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit AugLinearClassifier\n",
    "Fitting AugLinear is a simple function call! AugLinear takes a few hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = AugLinearClassifier(\n",
    "    checkpoint='textattack/distilbert-base-uncased-rotten-tomatoes',\n",
    "    ngrams=2,\n",
    "    all_ngrams=True,  # also use lower-order ngrams\n",
    ")\n",
    "m.fit(dset['text'], dset['label'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "We now have a linear model of ngrams. The `fit` function above has precomputed the linear coefficients for ngrams it saw during training and saved them to `m.coefs_dict_` Let's take a look at some of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total ngram coefficients: ', len(m.coefs_dict_))\n",
    "print('Most positive ngrams')\n",
    "for k, v in sorted(m.coefs_dict_.items(), key=lambda item: item[1], reverse=True)[:8]:\n",
    "    print('\\t', k, round(v, 2))\n",
    "print('Most negative ngrams')\n",
    "for k, v in sorted(m.coefs_dict_.items(), key=lambda item: item[1])[:8]:\n",
    "    print('\\t', k, round(v, 2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions\n",
    "Now, let's take a look at how we make predictions. This is very fast, as it just uses the precomputed dictionary `m.coefs_dict_`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = m.predict(dset['text'])\n",
    "print('acc_train', np.mean(preds == dset['label']))\n",
    "preds_proba = m.predict_proba(dset['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = m.predict(dset_val['text'])\n",
    "print('acc_val', np.mean(preds == dset_val['label']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: we may want to infer the coefficients for ngrams we didn't see during training. To do this, we call the `cache_linear_coefs` function on the inputs for the test set. This adds the values for the unseen coefficients to the dictionary `m.coefs_dict_`. Then we can call `predict` as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.cache_linear_coefs(dset_val['text'])\n",
    "preds = m.predict(dset_val['text'])\n",
    "print('acc_val', np.mean(preds == dset_val['label']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aug-Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imodelsx.augtree.data\n",
    "\n",
    "# set  your openai key\n",
    "import openai\n",
    "openai.api_key = open('/home/chansingh/.OPENAI_KEY', 'r').read().strip()\n",
    "\n",
    "# pepare data\n",
    "X_text = list(dset['text'])\n",
    "# optionally, convert data to ngrams\n",
    "X, _, feature_names = imodelsx.augtree.data.convert_text_data_to_counts_array(\n",
    "    X_text, [], ngrams=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = AugTreeClassifier(\n",
    "    max_depth=2,  # depth of the tree\n",
    "    max_features=1,\n",
    "    # this tells the classifier to actually use the llm (defaults to text-davinci-003)\n",
    "    refinement_strategy='llm',\n",
    "    verbose=True,\n",
    "    # folder to store cached ngram expansions\n",
    "    cache_expansions_dir='/home/chansigh/aug-models/augtree/results/gpt3_cache',\n",
    ")\n",
    "m.fit(X=X, y=dset['label'], feature_names=feature_names, X_text=X_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(m)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".embgam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "559535f78d940c882783b39501b2581b5193373045707e5f8a51d046029cfd38"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
